from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from contextlib import asynccontextmanager
import ml_models  
from fastapi.middleware.cors import CORSMiddleware

# 1. ØªØ¹Ø±ÙŠÙ Ø´ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
class CVRequest(BaseModel):
    cv_text: str

class VideoRequest(BaseModel):
    video_url: str

# 2. Ø¥Ø¯Ø§Ø±Ø© Ø¯ÙˆØ±Ø© Ø­ÙŠØ§Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª)
@asynccontextmanager
async def lifespan(app: FastAPI):
    print("ğŸš€ Starting up AI Service...")
    ml_models.load_models()  
    yield
    print("ğŸ›‘ Shutting down AI Service...")

# 3. Ø¥Ù†Ø´Ø§Ø¡ ØªØ·Ø¨ÙŠÙ‚ FastAPI (Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·!)
app = FastAPI(lifespan=lifespan)

# 4. Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù€ Middleware (Ù„Ø§Ø²Ù… ØªÙƒÙˆÙ† Ø¨Ø¹Ø¯ ØªØ¹Ø±ÙŠÙ app ÙˆÙ‚Ø¨Ù„ Ø§Ù„Ù€ routes)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 5. Ø§Ù„Ù€ Routes
@app.get("/")
def read_root():
    return {"status": "AI Service is Running", "models_loaded": True}

@app.post("/analyze-cv")
async def analyze_cv_endpoint(request: CVRequest):
    try:
        analysis = ml_models.generate_resume_text(request.cv_text)
        parsed_result = ml_models.parse_model_response(analysis)
        
        if parsed_result:
            return parsed_result
        return {"raw_text": analysis, "error": "Could not parse JSON properly"}
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze-interview")
async def analyze_video_endpoint(request: VideoRequest):
    try:
        result = ml_models.analyze_interview(request.video_url)
        return {"analysis": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))